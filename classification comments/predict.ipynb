{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.layers import Dropout,SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "types=['__label__Sarcasm ','__label__Positive ','__label__Negative ','__label__Neutral ']\n",
    "import pickle\n",
    "with open('tokenizerClear.pickle', 'rb') as handle:\n",
    "        tokenize = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_from_one_xtrain(sample):\n",
    "    result=[]\n",
    "    summ=0\n",
    "#     if len(sample.split())<200:\n",
    "#         X=sample+\" \"\n",
    "#         X=X*int(200/len(X.split()))\n",
    "#         sample=X\n",
    "    for word in sample.split():\n",
    "#         for ch in word:\n",
    "    \n",
    "        summ+=1\n",
    "        try: \n",
    "#             feature=np.sum(model.wv[word])\n",
    "            result.append(tokenize.word_index[word])\n",
    "        except:\n",
    "                feature=0\n",
    "        if summ==50:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_from_all_xtrain(samples):\n",
    "    res=[]\n",
    "    for sample in samples:\n",
    "        s=get_feature_from_one_xtrain(sample)\n",
    "\n",
    "        if(len(s)<50):\n",
    "            \n",
    "            for i in range(50-len(s)):\n",
    "                x=np.zeros(300,dtype=np.float64)\n",
    "                s.append(0)\n",
    "            \n",
    "#         x=np.zeros(20,dtype=np.float64)\n",
    "#         for i in range(20):\n",
    "#             if(i <len(s)):\n",
    "                \n",
    "#                 x[i]=s[i]\n",
    "        res.append(s)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vision\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"model_FINAL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentenc,model):\n",
    "    tt=get_feature_from_one_xtrain(sentenc)\n",
    "    for i in range(50-len(tt)):\n",
    "        tt.append(0)\n",
    "    tt=np.array(tt)\n",
    "    tt=tt.reshape(1,50)\n",
    "    print(types[np.argmax(model.predict([tt]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__Positive \n"
     ]
    }
   ],
   "source": [
    "predict_sentence(\"راائع جميل ممتاز\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
